---
######################################################################################################
# DO NOT MODIFY THIS FILE ANYWHERE OTHER THAN WITHIN THE CUSTOMIZE BLOCKS
#
#
# New services are acceptable
#
# Profiles
# We use the profiles "development" and "competition"
# All containers added by competitors must include the appropriate profiles
# At competition time only the `--profile competition` will be used
# This will cause the LiteLLM proxy to disappear.
# Competitors should be using the AIXCC_LITELLM_HOSTNAME environment variable
# for accessing LiteLLM, so we can swap the URL at competition time.
#
######################################################################################################

include:
  - path:
      - sandbox/compose.yaml

#############
### CUSTOMIZE
#############


### Additional services are welcomed, just make sure to use the supplied variables and profile names
services:
  crs:
    labels:
      kompose.serviceaccount-name: "crs"  # make sure to use this label if you want your CRS to have K8S API access
    networks:
      - crs-internal  # Competitors: You MUST use this network only for any containers you add to your CRS.
    profiles:
      - development
      - competition
    # Competitors: You MUST change crs-sandbox to your repo name, change replace-me-crs to your image name, and be versioned pinned to the release intended for competition.
    # The example show uses RELEASE_TAG variable if it is set.
    # The `-` before `v1.0.*` is used with interpolation to specify that v1.0.* should be used if RELEASE_TAG is not set.
    # The .github/workflows/package.yaml script will set the RELEASE_TAG environment variable so it is used correctly on release.
    image: ghcr.io/aixcc-sc/asc-crs-mindrake/brainbox:${RELEASE_TAG-v1.0.8}
    # Competitors: All services that are expected to have a clean exit must have restart: on-failure
    restart: on-failure
    build:
      context: .  # Note that this uses the base folder for context, you may not need this for your CRS
      # Competitors: You MUST change to your Dockerfile location for your CRS.
      # This points to the mock_crs by default.
      dockerfile: crs/src/Dockerfile
      # Competitors: You will need to change this command to trigger your CRS.
      # If you have multiple containers for your CRS you must design your own
      # orchestration and synchronisation mechanisms.
    command: ["python3", "py/run.py"]
    volumes:
      #################################################################################
      ### THESE VOLUMES MUST BE INCLUDED WITHOUT MODIFICATION TO ALL CRS CONTAINERS ###
      # A CRS MUST copy CP repositories from `AIXCC_CP_ROOT` to a writable location such as
      # `AIXCC_CRS_SCRATCH_SPACE` for building and testing CPs.
      # A CRS MUST not modify settings within this section.
      - type: bind
        source: ${PWD}/crs_scratch
        target: /crs_scratch
        bind:
          propagation: rshared
      - ./cp_root:/cp_root
      #################################################################################
    environment:
      # These values will be modified automatically at competition time
      - DOCKER_HOST=tcp://dind:2375
      - AIXCC_LITELLM_HOSTNAME=http://litellm
      - AIXCC_API_HOSTNAME=http://iapi:8080
      - AIXCC_CP_ROOT=/cp_root
      - AIXCC_CRS_SCRATCH_SPACE=/crs_scratch
      - LITELLM_KEY=sk-1234
    depends_on:
      iapi:
        condition: service_healthy

#############
### CUSTOMIZE
#############
